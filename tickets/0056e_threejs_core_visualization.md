# Ticket 0056e: Three.js Core Visualization

## Status
- [x] Draft
- [x] Ready for Implementation
- [ ] Implementation Complete — Awaiting Review
- [ ] Merged / Complete

**Current Phase**: Ready for Implementation
**Type**: Feature
**Priority**: Medium
**Assignee**: TBD
**Created**: 2026-02-11
**Updated**: 2026-02-12
**Generate Tutorial**: No
**Parent Ticket**: [0056_browser_simulation_replay](0056_browser_simulation_replay.md)
**Depends On**: [0056d_fastapi_backend](0056d_fastapi_backend.md), [0056k_example_workflow_test_recording](0056k_example_workflow_test_recording.md)

---

## Overview

Build the core Three.js web application that loads simulation recordings and provides frame-by-frame playback of rigid body motion. This ticket covers scene setup, body rendering, transform updates, playback controls, and camera interaction.

**Frontend approach**: Vanilla JavaScript with ES module imports from CDN (Three.js, Chart.js). No React/Vue/npm build tooling. The frontend is a specialized visualization tool, not a general web application.

### Two-Database Architecture

The replay system uses two separate databases:

| Database | Role | Generated By | Contains |
|----------|------|-------------|----------|
| **Asset database** (input) | Simulation input — geometry definitions | `msd-asset-gen` | MeshRecord, ObjectRecord, MaterialRecord |
| **Recording database** (output) | Simulation output — physics data | `DataRecorder` via simulation | Frames, states, collisions, energies, solver diagnostics, static asset records |

The link between them is `AssetPhysicalStaticRecord.asset_id` in the recording database, which maps to `ObjectRecord.id` in the asset database. This lets the replay viewer resolve visual geometry for each body.

---

## Requirements

### R0: Backend Prerequisites — Two-Database Wiring

Before the frontend can render bodies, the backend needs to support the two-database architecture.

#### R0a: Record AssetPhysicalStaticRecord at spawn time

**File**: `msd/msd-sim/src/DataRecorder/DataRecorder.cpp`

`recordStaticAsset()` currently only writes `AssetInertialStaticRecord` (mass, restitution, friction). It must also write `AssetPhysicalStaticRecord` (body_id, asset_id, is_environment) so the recording captures which asset geometry each body uses.

`AssetPhysical::toStaticRecord(bool isEnvironment)` already exists and creates the record. `AssetInertial` inherits from `AssetPhysical`, so `asset.toStaticRecord(false)` is available.

#### R0b: Update generate_test_recording.cpp to use Engine + AssetRegistry

**File**: `replay/tools/generate_test_recording.cpp`

The current generator bypasses the asset system entirely — it creates ConvexHulls manually with hardcoded asset IDs. Change it to:

1. Run `msd-asset-gen` first (or use a pre-built asset database)
2. Create `Engine` with the asset database path (uses `AssetRegistry` internally)
3. Spawn objects via `engine.spawnInertialObject("cube", position, orientation)` — this passes the real `ObjectRecord.id` as the asset_id
4. Enable recording on the Engine's WorldModel
5. Run the simulation

This ensures the recording's `AssetPhysicalStaticRecord.asset_id` matches `ObjectRecord.id` in the asset database.

#### R0c: Add asset database path to FastAPI config

**File**: `replay/replay/config.py`

Add `MSD_ASSETS_DB` environment variable for the asset (input) database path. The config should provide:
- `recordings_dir` — directory of recording (output) databases (existing)
- `assets_db_path` — path to the asset (input) database (new)

#### R0d: Update GeometryService to read from asset database

**File**: `replay/replay/services/geometry_service.py`

Change `GeometryService.__init__()` to accept the **asset database path** instead of the recording database path. The `/assets` endpoint reads `MeshRecord` / `ObjectRecord` from the asset database, not the recording.

The endpoint should also accept an optional `asset_ids` query parameter to filter — the frontend can pass the `asset_id` values from `AssetPhysicalStaticRecord` to load only the geometries it needs.

#### R0e: Update start_server.sh

**File**: `replay/start_server.sh`

Add asset database generation step:
1. Build `generate_assets` if needed
2. Run `generate_assets` to produce `replay/recordings/assets.db`
3. Export `MSD_ASSETS_DB=replay/recordings/assets.db`
4. Build and run `generate_test_recording` (uses asset DB)
5. Start uvicorn

### R1: Scene Setup

- Three.js scene with ambient + directional lighting
- Ground grid (GridHelper) for spatial reference
- Axis helpers (AxesHelper) for orientation reference
- WebGL renderer with antialiasing
- Responsive canvas (resize with window)

### R2: Body Rendering

- Load body metadata from `/simulations/{id}/metadata` — get `asset_id` for each body
- Load geometry from `/simulations/{id}/assets` endpoint (reads from asset database)
- Create Three.js `BufferGeometry` from flat position arrays
- Compute vertex normals via `geometry.computeVertexNormals()`
- Distinct materials for dynamic (blue, opaque) vs environment (gray, transparent) bodies
- Bodies stored in a `Map<bodyId, THREE.Mesh>` for efficient per-frame updates

### R3: Frame-by-Frame Transform Updates

- Fetch frame data from REST API
- Update each body's `position` and `quaternion` from frame state
- Quaternion convention: API returns `{w, x, y, z}`, Three.js constructor takes `(x, y, z, w)` — reorder on the frontend

### R4: Playback Controls

- **Play/Pause** button
- **Step Forward/Back** buttons (single frame)
- **Timeline scrubber** (slider showing current frame position)
- **Speed control** (0.25x, 0.5x, 1x, 2x, 4x)
- **Frame counter** display (current frame / total frames)
- **Simulation time** display
- Keyboard shortcuts: Space (play/pause), Left/Right arrows (step), +/- (speed)

### R5: Frame Data Buffering

- Prefetch frames ahead of playback position using bulk range endpoint
- Cache fetched frames in memory (`Map<frameId, FrameData>`)
- Buffer size: ~50 frames ahead of current position
- Request new batch when buffer runs low

### R6: Camera Controls

- Three.js OrbitControls (orbit, pan, zoom)
- Reset camera button to return to default view
- Default camera position looking at scene center from above-front

### R7: Simulation Selection

- Dropdown or list to select which recording to load
- Populated from `/api/v1/simulations` endpoint
- Loading indicator while geometry and initial frames load

---

## Files to Create

All frontend files under `replay/static/`:

| File | Purpose |
|------|---------|
| `index.html` | Main HTML page with viewport and controls UI (replaces placeholder) |
| `css/style.css` | Layout and control styling |
| `js/app.js` | Main entry point, initialization |
| `js/scene.js` | SceneManager — Three.js scene, bodies, rendering |
| `js/playback.js` | PlaybackController — timeline, play/pause/step/speed |
| `js/data.js` | DataLoader — REST API client with frame buffering |
| `js/ui.js` | UI controls binding and updates |

## Files to Modify

| File | Change |
|------|--------|
| `msd/msd-sim/src/DataRecorder/DataRecorder.cpp` | `recordStaticAsset()`: also write `AssetPhysicalStaticRecord` (R0a) |
| `replay/tools/generate_test_recording.cpp` | Use `Engine` + `AssetRegistry` instead of raw `WorldModel` (R0b) |
| `replay/replay/config.py` | Add `MSD_ASSETS_DB` env var (R0c) |
| `replay/replay/services/geometry_service.py` | Read from asset database (R0d) |
| `replay/replay/routes/assets.py` | Pass asset DB path to GeometryService (R0d) |
| `replay/start_server.sh` | Add asset-gen step, export `MSD_ASSETS_DB` (R0e) |

---

## Test Plan

### Manual Testing

1. Run `start_server.sh` (generates asset DB, recording DB, starts server)
2. Open browser to `http://localhost:8000`
3. Verify: scene renders with grid and axes
4. Verify: bodies appear in correct initial positions (cube above floor)
5. Verify: play button advances frames, cube falls and bounces
6. Verify: step forward/back moves one frame at a time
7. Verify: timeline scrubber jumps to arbitrary frame
8. Verify: speed control changes playback rate
9. Verify: camera orbit/pan/zoom works
10. Verify: simulation selector loads different recordings

### API Verification

```bash
# Verify asset_id is recorded
sqlite3 replay/recordings/test_cube_drop.db \
  "SELECT * FROM AssetPhysicalStaticRecord;"
# Should show: body_id, asset_id (matching ObjectRecord.id), is_environment

# Verify geometry endpoint returns data
curl http://localhost:8000/api/v1/simulations/test_cube_drop/assets | python -m json.tool
```

### Automated Testing

Automated browser testing is out of scope for v1. Manual verification is sufficient for a development-only debugging tool.

---

## Acceptance Criteria

1. [ ] **AC1**: `AssetPhysicalStaticRecord` recorded at spawn with correct `asset_id`
2. [ ] **AC2**: `generate_test_recording` uses `Engine` + `AssetRegistry` (real asset IDs)
3. [ ] **AC3**: `/assets` endpoint returns geometry from asset database
4. [ ] **AC4**: Three.js scene renders with lighting, grid, and axes
5. [ ] **AC5**: Bodies loaded from asset endpoint and rendered correctly
6. [ ] **AC6**: Frame playback updates body positions and orientations smoothly
7. [ ] **AC7**: Play/pause/step/scrub controls functional
8. [ ] **AC8**: Speed control works (0.25x to 4x)
9. [ ] **AC9**: Camera controls (orbit, pan, zoom) work
10. [ ] **AC10**: Frame buffering prevents playback stutter
11. [ ] **AC11**: Multiple recordings can be loaded via simulation selector

---

## Workflow Log

### Draft → Ready for Implementation
- **Started**: 2026-02-12 12:00
- **Completed**: 2026-02-12 12:00
- **Branch**: N/A (not yet created)
- **PR**: N/A
- **Notes**: Ticket has well-defined requirements and does not require design phase. Ready for implementation. No math design or architectural design needed - this is a frontend implementation with clear specifications for Three.js scene setup, playback controls, and REST API integration.

---

## Human Feedback

{Add feedback here at any point. Agents will read this section.}
