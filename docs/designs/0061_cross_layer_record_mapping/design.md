# Design: Cross-Layer Record Mapping Indexer

## Summary

Build a traceability indexer that extracts field lists from C++ transfer records (BOOST_DESCRIBE_STRUCT), SQL schema (auto-generated by cpp_sqlite), pybind11 bindings, and Pydantic models, then stores cross-layer mappings in the traceability database. This provides visibility into which fields are connected across layers and which have drifted, without requiring code generation changes.

## Architecture Changes

### PlantUML Diagram
See: `./0061_cross_layer_record_mapping.puml`

### New Components

#### BoostDescribeParser
- **Purpose**: Extract field lists from BOOST_DESCRIBE_STRUCT macros in msd-transfer headers
- **Location**: `scripts/traceability/index_record_mappings.py` (as a function, not a separate class)
- **Key interfaces**:
  ```python
  def parse_boost_describe_fields(header_content: str) -> list[FieldInfo]:
      """
      Extract field names and types from BOOST_DESCRIBE_STRUCT macro.

      Args:
          header_content: Full text of a .hpp file

      Returns:
          List of FieldInfo dicts with:
          - field_name: Field identifier
          - field_type: C++ type (primitive, ForeignKey<T>, RepeatedField<T>, nested record)
          - is_foreign_key: True if ForeignKey<T>
          - is_repeated: True if RepeatedField<T>
      """
      pass
  ```
- **Dependencies**: Python `re` module for regex parsing
- **Error handling**: Skip malformed macros with warning, continue processing other records

#### PybindParser
- **Purpose**: Extract field mappings from pybind11 .def_readonly() and .def_property_readonly() calls
- **Location**: `scripts/traceability/index_record_mappings.py` (as a function)
- **Key interfaces**:
  ```python
  def parse_pybind_bindings(bindings_content: str) -> dict[str, list[FieldInfo]]:
      """
      Extract field bindings from record_bindings.cpp.

      Args:
          bindings_content: Full text of record_bindings.cpp

      Returns:
          Dict mapping C++ record name to list of exposed fields:
          - field_name: Python attribute name
          - source_field: C++ field name (may differ for ForeignKey transformations)
          - is_property: True if def_property_readonly, False if def_readonly
      """
      pass
  ```
- **Dependencies**: Python `re` module
- **Error handling**: Skip unparseable bindings with warning

#### PydanticParser
- **Purpose**: Extract field lists from Pydantic model class definitions
- **Location**: `scripts/traceability/index_record_mappings.py` (as a function)
- **Key interfaces**:
  ```python
  def parse_pydantic_models(models_content: str) -> dict[str, list[FieldInfo]]:
      """
      Extract field definitions from Pydantic BaseModel classes.

      Args:
          models_content: Full text of models.py

      Returns:
          Dict mapping Pydantic class name to list of fields:
          - field_name: Python attribute name
          - field_type: Python type annotation
          - cpp_record: Inferred C++ record name (via docstring or naming convention)
      """
      pass
  ```
- **Dependencies**: Python `ast` module for AST parsing (safer than regex for Python)
- **Error handling**: Skip unparseable classes with warning

#### index_record_mappings.py
- **Purpose**: Main indexer script that orchestrates parsing and database population
- **Location**: `scripts/traceability/index_record_mappings.py`
- **Key interfaces**:
  ```python
  def main(db_path: str, repo_root: str) -> None:
      """
      Index record field mappings from all four layers.

      1. Parse C++ transfer records (msd-transfer/src/*.hpp)
      2. Parse pybind11 bindings (msd-pybind/src/record_bindings.cpp)
      3. Parse Pydantic models (replay/replay/models.py)
      4. Cross-reference to build mapping tables
      5. Populate record_layer_fields and record_layer_mapping tables
      6. Rebuild FTS index

      Args:
          db_path: Path to traceability.db
          repo_root: Path to repository root
      """
      pass
  ```
- **Dependencies**:
  - `traceability_schema` module for database schema
  - Python standard library (`pathlib`, `re`, `ast`, `sqlite3`)
- **Thread safety**: Single-threaded, idempotent (safe to re-run)
- **Error handling**:
  - Log parsing errors but continue processing
  - Abort on database errors
  - Exit code 0 if successful, 1 if critical errors

### Modified Components

#### traceability_schema.py
- **Current location**: `scripts/traceability/traceability_schema.py`
- **Changes required**:
  1. Add `record_layer_fields` table definition to `create_schema()`:
     ```sql
     CREATE TABLE IF NOT EXISTS record_layer_fields (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         record_name TEXT NOT NULL,       -- e.g., "EnergyRecord"
         layer TEXT NOT NULL,             -- "cpp", "sql", "pybind", "pydantic"
         field_name TEXT NOT NULL,        -- field name in that layer
         field_type TEXT,                 -- type info where available
         source_field TEXT,               -- corresponding C++ field (NULL for cpp layer)
         notes TEXT                       -- e.g., "joined from SimulationFrameRecord"
     );
     CREATE INDEX IF NOT EXISTS idx_rlf_record ON record_layer_fields(record_name);
     CREATE INDEX IF NOT EXISTS idx_rlf_layer ON record_layer_fields(layer);
     ```
  2. Add `record_layer_mapping` table definition:
     ```sql
     CREATE TABLE IF NOT EXISTS record_layer_mapping (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         record_name TEXT NOT NULL UNIQUE, -- C++ record name
         pydantic_model TEXT,              -- corresponding Pydantic class (may be NULL)
         pybind_class TEXT,                -- corresponding pybind class (may be NULL)
         sql_table TEXT                    -- corresponding SQL table name
     );
     CREATE INDEX IF NOT EXISTS idx_rlm_pydantic ON record_layer_mapping(pydantic_model);
     ```
  3. Add FTS5 index for field search:
     ```sql
     CREATE VIRTUAL TABLE IF NOT EXISTS record_layer_fields_fts USING fts5(
         field_name,
         field_type,
         notes,
         content=record_layer_fields,
         content_rowid=id,
         tokenize='porter unicode61'
     );
     ```
  4. Increment `SCHEMA_VERSION` to 2
- **Backward compatibility**: Safe to upgrade — new tables don't affect existing ones

#### traceability_server.py
- **Current location**: `scripts/traceability/traceability_server.py`
- **Changes required**:
  1. Add `get_record_mappings` MCP tool:
     ```python
     def get_record_mappings(record_name: str) -> dict:
         """
         Return all four layers' field lists for a record with drift analysis.

         Returns:
             {
                 "record": record_name,
                 "layers": {
                     "cpp": [{"field": "linear_ke", "type": "double"}],
                     "sql": [{"field": "linear_ke", "type": "REAL"}],
                     "pybind": [{"field": "linear_ke", "source": "linear_ke"}],
                     "pydantic": [{"field": "linear_ke", "type": "float"}]
                 },
                 "drift": {
                     "missing_in_pybind": [],
                     "missing_in_pydantic": ["acceleration"],
                     "naming_mismatches": [
                         {"cpp": "penetrationDepth", "pydantic": "penetration_depth"}
                     ]
                 }
             }
         ```
  2. Add `check_record_drift` MCP tool:
     ```python
     def check_record_drift() -> list[dict]:
         """
         Return all records with fields missing from downstream layers.

         Returns:
             [
                 {
                     "record": "InertialStateRecord",
                     "missing_in_pybind": [],
                     "missing_in_pydantic": ["acceleration", "quaternionRate"]
                 }
             ]
         """
         pass
     ```
  3. Register new tools in MCP server tool list
- **Backward compatibility**: New tools only, no changes to existing tools

### Integration Points
| New Component | Existing Component | Integration Type | Notes |
|---------------|-------------------|------------------|-------|
| index_record_mappings.py | traceability_schema.py | Import | Uses `create_schema()` to ensure tables exist |
| index_record_mappings.py | traceability.db | Database write | Populates new tables |
| traceability_server.py | record_layer_fields | Database read | Queries for MCP tools |
| index_record_mappings.py | msd-transfer/*.hpp | File read | Parses BOOST_DESCRIBE_STRUCT macros |
| index_record_mappings.py | msd-pybind/record_bindings.cpp | File read | Parses pybind11 bindings |
| index_record_mappings.py | replay/models.py | File read | Parses Pydantic models |

## Test Impact

### Existing Tests Affected
None — this is a new tooling feature with no impact on existing code or tests.

### New Tests Required

#### Unit Tests
| Component | Test Case | What It Validates |
|-----------|-----------|-------------------|
| BoostDescribeParser | parse_simple_struct | Extracts fields from basic BOOST_DESCRIBE_STRUCT |
| BoostDescribeParser | parse_foreign_key_fields | Identifies ForeignKey<T> fields and extracts target type |
| BoostDescribeParser | parse_repeated_fields | Identifies RepeatedField<T> fields |
| BoostDescribeParser | parse_nested_records | Handles nested sub-records (e.g., CoordinateRecord inside InertialStateRecord) |
| PybindParser | parse_def_readonly | Extracts direct field mappings |
| PybindParser | parse_def_property_readonly | Extracts computed/FK property mappings |
| PybindParser | parse_fk_lambda_pattern | Detects ForeignKey transformation (e.g., `body.id` → `body_id`) |
| PydanticParser | parse_class_definition | Extracts field names and type annotations |
| PydanticParser | infer_cpp_record_name | Correctly infers C++ record from class name or docstring |
| PydanticParser | handle_optional_fields | Parses `field: Type \| None` annotations |
| index_record_mappings.py | populate_layer_fields | All layers' fields correctly inserted into record_layer_fields |
| index_record_mappings.py | populate_layer_mapping | Cross-layer mappings correctly inserted |
| index_record_mappings.py | idempotency | Re-running indexer produces same result (no duplicates) |

#### Integration Tests
| Test Case | Components Involved | What It Validates |
|-----------|---------------------|-------------------|
| full_indexer_run | index_record_mappings.py + traceability.db | All existing records indexed without errors |
| mcp_get_record_mappings | traceability_server.py + database | MCP tool returns correct four-layer comparison for EnergyRecord |
| mcp_check_record_drift | traceability_server.py + database | MCP tool correctly identifies missing Pydantic fields |
| cmake_build_target | CMake + indexer script | `cmake --build --preset debug-traceability` runs new indexer |

## Open Questions

### Design Decisions (Human Input Needed)

1. **SQL Schema Extraction Method**
   - Option A: Parse cpp_sqlite auto-generated schema from BOOST_DESCRIBE (no schema querying needed) — Pros: Simple, no runtime dependency. Cons: Assumes 1:1 mapping of C++ types to SQL types.
   - Option B: Query SQLite schema from an existing .db file generated by cpp_sqlite — Pros: Accurate SQL type names. Cons: Requires running `generate_assets` first.
   - **Recommendation**: Option A (parse from BOOST_DESCRIBE). SQL types are deterministic from C++ types (double→REAL, uint32_t→INTEGER, std::string→TEXT, ForeignKey<T>→INTEGER, RepeatedField<T>→junction table). This matches the existing pattern of indexers that don't depend on build artifacts.

2. **Naming Transformation Detection**
   - Option A: Hard-code known transformations (`camelCase` → `snake_case`, `ForeignKey<T> field` → `field_id`) — Pros: Fast, simple. Cons: Brittle if conventions change.
   - Option B: Use edit distance heuristics to detect likely matches (`penetrationDepth` vs `penetration_depth`) — Pros: More flexible. Cons: False positives possible.
   - **Recommendation**: Option A with explicit notes field. Hard-code the two known transformations (FK suffix, snake_case conversion) and store explanations in the `notes` column. This makes the transformation logic visible in the database.

3. **Intentional Omissions vs. Drift**
   - Some Pydantic models intentionally omit internal/diagnostic fields (e.g., `acceleration`, `quaternionRate` in InertialStateRecord are not exposed to the REST API).
   - Option A: Mark intentional omissions manually (separate config file or comment annotation in Pydantic classes) — Pros: Explicit. Cons: Requires maintenance.
   - Option B: Report all missing fields and let human review determine intent — Pros: Zero config. Cons: Noisy output.
   - **Recommendation**: Option B. The `check_record_drift()` tool returns all missing fields. Humans can ignore known intentional omissions (this is a visibility tool, not an enforcement tool).

4. **FTS Index Scope**
   - Option A: Index only `field_name` and `notes` for quick field search — Pros: Small index. Cons: Can't search by type.
   - Option B: Index `field_name`, `field_type`, and `notes` — Pros: More search flexibility. Cons: Slightly larger index.
   - **Recommendation**: Option B. Type search is useful (e.g., "find all ForeignKey<SimulationFrameRecord> fields"). The index size increase is negligible (~15 records × 4 layers = ~60 rows).

### Prototype Required
None — this is a straightforward indexer following the existing pattern from `index_decisions.py` and `index_symbols.py`. The parsing logic is regex-based for C++ and AST-based for Python, both well-understood.

### Requirements Clarification
1. **Should the indexer track historical changes to record schemas?**
   - Currently designed as snapshot indexer (current state only).
   - Could be extended to snapshot schemas at each commit (similar to `symbol_snapshots`).
   - **Recommendation**: Start with current-state-only. Historical tracking can be added later if needed.

## Implementation Notes

### BOOST_DESCRIBE Parsing Strategy
The macro format is predictable:
```cpp
BOOST_DESCRIBE_STRUCT(RecordName,
                      (BaseClass),
                      (field1, field2, field3));
```

Regex pattern:
```python
BOOST_DESCRIBE_RE = re.compile(
    r"BOOST_DESCRIBE_STRUCT\s*\(\s*(\w+)\s*,\s*\([^)]*\)\s*,\s*\(([^)]+)\)\s*\)",
    re.MULTILINE
)
```

For each field, determine type by scanning backward from the macro to find declarations:
```cpp
cpp_sqlite::ForeignKey<AssetInertialStaticRecord> body;  // ForeignKey
double linear_ke{0.0};                                   // primitive
CoordinateRecord position;                               // nested record
```

### pybind11 Parsing Strategy
Two patterns to detect:
1. Direct field: `.def_readonly("field_name", &RecordType::field_name)`
2. Property (FK): `.def_property_readonly("field_id", [](const Record& r) { return r.field.id; })`

Regex for class blocks:
```python
PYBIND_CLASS_RE = re.compile(
    r'py::class_<msd_transfer::(\w+)>\(m, "(\w+)"\)(.*?)(?=py::class_|$)',
    re.DOTALL
)
```

Within each class block, extract `.def_readonly` and `.def_property_readonly`.

### Pydantic Parsing Strategy
Use Python `ast` module to parse models.py:
```python
import ast

tree = ast.parse(models_content)
for node in ast.walk(tree):
    if isinstance(node, ast.ClassDef):
        # Check if inherits from BaseModel
        for base in node.bases:
            if isinstance(base, ast.Name) and base.id == "BaseModel":
                # Extract fields from class body (ast.AnnAssign nodes)
```

### Database Schema Evolution
New tables are independent of existing traceability tables. Upgrade path:
1. Run `cmake --build --preset debug-traceability` — schema upgrade happens automatically in `create_schema()`
2. New tables are created if they don't exist (CREATE TABLE IF NOT EXISTS)
3. Existing data unaffected

### CMake Integration
Add new target in root `CMakeLists.txt` (following existing pattern):
```cmake
add_custom_target(
  trace-record-mappings
  COMMAND ${CMAKE_COMMAND} -E env
    PYTHONPATH=${CMAKE_SOURCE_DIR}/scripts/traceability
    ${Python_EXECUTABLE} ${CMAKE_SOURCE_DIR}/scripts/traceability/index_record_mappings.py
      ${CMAKE_BINARY_DIR}/docs/traceability.db
      --repo ${CMAKE_SOURCE_DIR}
  DEPENDS trace-git
  WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}
  COMMENT "Indexing record field mappings"
)
```

Add to `debug-traceability` preset dependencies.

## Example Output

### get_record_mappings("EnergyRecord")
```json
{
  "record": "EnergyRecord",
  "layers": {
    "cpp": [
      {"field": "id", "type": "uint32_t", "notes": "inherited from BaseTransferObject"},
      {"field": "body", "type": "ForeignKey<AssetInertialStaticRecord>"},
      {"field": "linear_ke", "type": "double"},
      {"field": "rotational_ke", "type": "double"},
      {"field": "potential_e", "type": "double"},
      {"field": "total_e", "type": "double"},
      {"field": "frame", "type": "ForeignKey<SimulationFrameRecord>"}
    ],
    "sql": [
      {"field": "id", "type": "INTEGER PRIMARY KEY"},
      {"field": "body_id", "type": "INTEGER", "notes": "ForeignKey → _id suffix"},
      {"field": "linear_ke", "type": "REAL"},
      {"field": "rotational_ke", "type": "REAL"},
      {"field": "potential_e", "type": "REAL"},
      {"field": "total_e", "type": "REAL"},
      {"field": "frame_id", "type": "INTEGER", "notes": "ForeignKey → _id suffix"}
    ],
    "pybind": [
      {"field": "id", "source": "id"},
      {"field": "body_id", "source": "body.id", "notes": "ForeignKey lambda"},
      {"field": "linear_ke", "source": "linear_ke"},
      {"field": "rotational_ke", "source": "rotational_ke"},
      {"field": "potential_e", "source": "potential_e"},
      {"field": "total_e", "source": "total_e"},
      {"field": "frame_id", "source": "frame.id", "notes": "ForeignKey lambda"}
    ],
    "pydantic": [
      {"field": "body_id", "type": "int"},
      {"field": "frame_id", "type": "int"},
      {"field": "simulation_time", "type": "float", "notes": "joined from SimulationFrameRecord"},
      {"field": "linear_ke", "type": "float"},
      {"field": "rotational_ke", "type": "float"},
      {"field": "potential_e", "type": "float"},
      {"field": "total_e", "type": "float"}
    ]
  },
  "drift": {
    "missing_in_pybind": [],
    "missing_in_pydantic": [],
    "naming_mismatches": [],
    "extra_in_pydantic": [
      {"field": "simulation_time", "reason": "joined from SimulationFrameRecord via API query"}
    ]
  }
}
```

### check_record_drift()
```json
[
  {
    "record": "InertialStateRecord",
    "missing_in_pybind": [],
    "missing_in_pydantic": [
      "acceleration",
      "quaternionRate",
      "angularAcceleration"
    ],
    "reason": "Internal diagnostic fields not exposed to REST API"
  },
  {
    "record": "CollisionResultRecord",
    "missing_in_pybind": [],
    "missing_in_pydantic": [],
    "naming_mismatches": [
      {"cpp": "penetrationDepth", "pydantic": "penetration_depth"}
    ]
  }
]
```

---

## Design Review

**Reviewer**: Design Review Agent
**Date**: 2026-02-13
**Status**: APPROVED WITH NOTES
**Iteration**: 0 of 1 (no revision needed)

### Criteria Assessment

#### Architectural Fit

| Criterion | Pass/Fail | Notes |
|-----------|-----------|-------|
| Naming conventions | ✓ | Python module naming follows conventions (snake_case functions, PascalCase classes). Function names are clear and descriptive. |
| Namespace organization | ✓ | New indexer follows existing pattern in `scripts/traceability/`. Database tables use appropriate naming prefix (`record_layer_*`). |
| File/folder structure | ✓ | Single new file `index_record_mappings.py` matches pattern from `index_decisions.py`, `index_symbols.py`. Schema changes in existing `traceability_schema.py`. |
| Dependency direction | ✓ | No circular dependencies. Indexer reads source files unidirectionally. Database schema is independent. MCP server reads database tables. |

#### C++ Design Quality

*Note: This is a Python tooling feature with no C++ code. C++ design quality assessment is N/A.*

| Criterion | Pass/Fail | Notes |
|-----------|-----------|-------|
| Python code quality | ✓ | Design proposes type hints (`str \| None`, `list[dict]`), appropriate use of `ast` module for Python parsing (safer than regex), clear separation of parsing functions. |
| Error handling | ✓ | Design specifies skip-with-warning for malformed inputs, abort on database errors, proper exit codes. |
| Module organization | ✓ | Functions appropriately scoped (parsing functions at module level, orchestration in `main()`). |

#### Feasibility

| Criterion | Pass/Fail | Notes |
|-----------|-----------|-------|
| Parsing complexity | ✓ | BOOST_DESCRIBE parsing is regex-based (well-defined format). pybind11 parsing is regex-based (predictable patterns). Pydantic parsing uses Python AST (robust). All three approaches are proven. |
| Database schema | ✓ | Schema design is straightforward. Two new tables with appropriate indexes. FTS5 index follows existing pattern. Safe upgrade path (CREATE TABLE IF NOT EXISTS). |
| Build integration | ✓ | CMake target pattern matches existing `trace-git`, `trace-symbols`, `trace-decisions`. PYTHONPATH setup is standard. |
| Runtime dependencies | ✓ | All dependencies are already present (Python standard library: `re`, `ast`, `pathlib`, `sqlite3`). No new external dependencies. |
| Thread safety | ✓ | Single-threaded indexer (stated explicitly). Idempotent (safe to re-run). |

#### Testability

| Criterion | Pass/Fail | Notes |
|-----------|-----------|-------|
| Isolation possible | ✓ | Parsing functions are pure (input string → output dict). Can be unit tested independently with sample inputs. |
| Mockable dependencies | ✓ | Database connection can be mocked. File reading can be stubbed with string content. |
| Observable state | ✓ | Database tables can be queried directly for verification. MCP tools provide programmatic access for integration tests. |
| Test coverage | ✓ | Design document specifies comprehensive unit tests (9 test cases for parsers) and integration tests (4 test cases for full workflow). |

### Risks Identified

| ID | Risk Description | Category | Likelihood | Impact | Mitigation | Prototype? |
|----|------------------|----------|------------|--------|------------|------------|
| R1 | BOOST_DESCRIBE regex may fail on unusual macro formatting (multi-line, comments) | Technical | Low | Low | Test against all existing msd-transfer headers. Fallback: skip with warning. | No |
| R2 | pybind11 binding patterns may evolve and break regex | Maintenance | Low | Medium | Use robust multi-line regex patterns. Version the script with ticket numbers to track compatibility. | No |
| R3 | Pydantic model docstrings may not reliably indicate C++ record name | Technical | Medium | Low | Fallback to naming convention (strip "Response" suffix, match PascalCase). Verified in implementation. | No |
| R4 | Intentional omissions flagged as drift causing noise | Maintenance | High | Low | Recommendation in design: report all, human reviews. Could add config file in future ticket if noise is excessive. | No |
| R5 | SQL type inference from C++ types may be incomplete | Technical | Low | Low | Design covers common types (double→REAL, uint32_t→INTEGER, ForeignKey→INTEGER). Unmapped types logged as warnings. | No |

### Notes for Implementation

1. **BOOST_DESCRIBE Parsing Robustness**: The design correctly identifies the macro format is predictable, but should handle edge cases:
   - Multi-line macro invocations (parentheses split across lines)
   - C-style comments between macro name and arguments
   - Whitespace variations (tabs vs spaces)
   - **Recommendation**: Test the regex against ALL existing headers in msd-transfer/src/ during implementation to verify coverage.

2. **ForeignKey Transformation Detection**: The design hard-codes FK suffix transformation (`ForeignKey<T> field` → `field_id`). This is correct and matches existing code patterns in record_bindings.cpp.
   - **Example verified**: `EnergyRecord::body` (ForeignKey) → pybind `.def_property_readonly("body_id", ...)` → Pydantic `body_id: int`
   - **Note**: This transformation is consistent across all existing records and unlikely to change.

3. **Naming Case Conversion**: The design mentions `camelCase` → `snake_case` but provides limited examples.
   - **Verified pattern**: `penetrationDepth` → `penetration_depth` in CollisionResultRecord
   - **Edge case to handle**: `pointA` → `point_a` (single letter suffix)
   - **Recommendation**: Use a robust case-splitting regex that handles both standard camelCase and single-letter suffixes.

4. **Pydantic Model Linkage**: The design proposes inferring C++ record names from Pydantic class names or docstrings.
   - **Observed pattern in models.py**: Class names generally match C++ record names minus "Record" suffix
     - Example: `EnergyRecord` (C++) → `EnergyPoint` (Pydantic) — **mismatch**
     - Example: `CollisionResultRecord` (C++) → `CollisionInfo` (Pydantic) — **mismatch**
   - **Recommendation**: Rely on docstrings ("From {RecordName}") where present. Naming heuristics are unreliable. This may result in NULL `pydantic_model` for some records — acceptable for a visibility tool.

5. **Schema Version Increment**: The design correctly specifies incrementing `SCHEMA_VERSION` to 2. This triggers proper upgrade behavior in existing database connections.

6. **FTS5 Index Content**: The design proposes indexing `field_name`, `field_type`, and `notes`. This is appropriate.
   - **Use case validated**: "find all ForeignKey<SimulationFrameRecord> fields" — searches `field_type` column
   - **Use case validated**: "find fields with transformation notes" — searches `notes` column

### Open Questions — Design Decisions Resolved

The design document lists 4 open questions. All recommendations are sound:

1. **SQL Schema Extraction** — Option A (parse from BOOST_DESCRIBE) is correct. cpp_sqlite type mapping is deterministic.
2. **Naming Transformation** — Option A (hard-code) is correct. Two transformations are well-established (FK suffix, snake_case).
3. **Intentional Omissions** — Option B (report all) is correct for a visibility tool. Noise can be filtered by user or future enhancement.
4. **FTS Index Scope** — Option B (include type) is correct. Type search is useful and index overhead is negligible.

**All recommendations approved.** No additional human input required on these questions.

### Prototype Guidance

**No prototypes required.**

**Rationale**: All components follow established patterns with proven technologies:
- BOOST_DESCRIBE parsing: regex on well-defined format (similar to existing DD block parsing in `index_decisions.py`)
- pybind11 parsing: regex on predictable patterns
- Pydantic parsing: Python `ast` module (robust, standard library)
- Database schema: SQLite with FTS5 (already used in existing traceability tables)
- MCP tool exposure: existing pattern from `search_decisions`, `get_decision` tools

All risks are low-to-medium likelihood with low-to-medium impact, and all have clear mitigation strategies that don't require prototyping.

### Summary

This design is **APPROVED WITH NOTES** for implementation.

**Strengths:**
- Follows existing traceability indexer patterns closely (`index_decisions.py`, `index_symbols.py`)
- Well-defined schema with appropriate indexes and FTS5 search capability
- Clear separation of concerns (parsing functions → database population → MCP exposure)
- Comprehensive test plan covering both unit and integration scenarios
- All open questions have sound recommendations that align with project conventions

**Minor concerns addressed in notes:**
- Pydantic model linkage may be incomplete (some records won't map via naming convention)
- Edge cases in camelCase → snake_case conversion should be tested
- BOOST_DESCRIBE regex should be validated against all existing headers

**Recommended next steps:**
1. Proceed to implementation following the design as specified
2. During implementation, validate BOOST_DESCRIBE regex against all msd-transfer headers
3. Test case-splitting regex against known examples (`pointA`, `pointB`, `penetrationDepth`)
4. Accept that some Pydantic model mappings may be NULL (tool is for visibility, not enforcement)

**Estimated implementation effort**: 4-6 hours (no prototypes required, straightforward indexer following existing pattern)
