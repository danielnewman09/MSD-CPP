# Design: Cross-Layer Record Mapping Indexer

## Summary

Build a traceability indexer that extracts field lists from C++ transfer records (BOOST_DESCRIBE_STRUCT), SQL schema (auto-generated by cpp_sqlite), pybind11 bindings, and Pydantic models, then stores cross-layer mappings in the traceability database. This provides visibility into which fields are connected across layers and which have drifted, without requiring code generation changes.

## Architecture Changes

### PlantUML Diagram
See: `./0061_cross_layer_record_mapping.puml`

### New Components

#### BoostDescribeParser
- **Purpose**: Extract field lists from BOOST_DESCRIBE_STRUCT macros in msd-transfer headers
- **Location**: `scripts/traceability/index_record_mappings.py` (as a function, not a separate class)
- **Key interfaces**:
  ```python
  def parse_boost_describe_fields(header_content: str) -> list[FieldInfo]:
      """
      Extract field names and types from BOOST_DESCRIBE_STRUCT macro.

      Args:
          header_content: Full text of a .hpp file

      Returns:
          List of FieldInfo dicts with:
          - field_name: Field identifier
          - field_type: C++ type (primitive, ForeignKey<T>, RepeatedField<T>, nested record)
          - is_foreign_key: True if ForeignKey<T>
          - is_repeated: True if RepeatedField<T>
      """
      pass
  ```
- **Dependencies**: Python `re` module for regex parsing
- **Error handling**: Skip malformed macros with warning, continue processing other records

#### PybindParser
- **Purpose**: Extract field mappings from pybind11 .def_readonly() and .def_property_readonly() calls
- **Location**: `scripts/traceability/index_record_mappings.py` (as a function)
- **Key interfaces**:
  ```python
  def parse_pybind_bindings(bindings_content: str) -> dict[str, list[FieldInfo]]:
      """
      Extract field bindings from record_bindings.cpp.

      Args:
          bindings_content: Full text of record_bindings.cpp

      Returns:
          Dict mapping C++ record name to list of exposed fields:
          - field_name: Python attribute name
          - source_field: C++ field name (may differ for ForeignKey transformations)
          - is_property: True if def_property_readonly, False if def_readonly
      """
      pass
  ```
- **Dependencies**: Python `re` module
- **Error handling**: Skip unparseable bindings with warning

#### PydanticParser
- **Purpose**: Extract field lists from Pydantic model class definitions
- **Location**: `scripts/traceability/index_record_mappings.py` (as a function)
- **Key interfaces**:
  ```python
  def parse_pydantic_models(models_content: str) -> dict[str, list[FieldInfo]]:
      """
      Extract field definitions from Pydantic BaseModel classes.

      Args:
          models_content: Full text of models.py

      Returns:
          Dict mapping Pydantic class name to list of fields:
          - field_name: Python attribute name
          - field_type: Python type annotation
          - cpp_record: Inferred C++ record name (via docstring or naming convention)
      """
      pass
  ```
- **Dependencies**: Python `ast` module for AST parsing (safer than regex for Python)
- **Error handling**: Skip unparseable classes with warning

#### index_record_mappings.py
- **Purpose**: Main indexer script that orchestrates parsing and database population
- **Location**: `scripts/traceability/index_record_mappings.py`
- **Key interfaces**:
  ```python
  def main(db_path: str, repo_root: str) -> None:
      """
      Index record field mappings from all four layers.

      1. Parse C++ transfer records (msd-transfer/src/*.hpp)
      2. Parse pybind11 bindings (msd-pybind/src/record_bindings.cpp)
      3. Parse Pydantic models (replay/replay/models.py)
      4. Cross-reference to build mapping tables
      5. Populate record_layer_fields and record_layer_mapping tables
      6. Rebuild FTS index

      Args:
          db_path: Path to traceability.db
          repo_root: Path to repository root
      """
      pass
  ```
- **Dependencies**:
  - `traceability_schema` module for database schema
  - Python standard library (`pathlib`, `re`, `ast`, `sqlite3`)
- **Thread safety**: Single-threaded, idempotent (safe to re-run)
- **Error handling**:
  - Log parsing errors but continue processing
  - Abort on database errors
  - Exit code 0 if successful, 1 if critical errors

### Modified Components

#### traceability_schema.py
- **Current location**: `scripts/traceability/traceability_schema.py`
- **Changes required**:
  1. Add `record_layer_fields` table definition to `create_schema()`:
     ```sql
     CREATE TABLE IF NOT EXISTS record_layer_fields (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         record_name TEXT NOT NULL,       -- e.g., "EnergyRecord"
         layer TEXT NOT NULL,             -- "cpp", "sql", "pybind", "pydantic"
         field_name TEXT NOT NULL,        -- field name in that layer
         field_type TEXT,                 -- type info where available
         source_field TEXT,               -- corresponding C++ field (NULL for cpp layer)
         notes TEXT                       -- e.g., "joined from SimulationFrameRecord"
     );
     CREATE INDEX IF NOT EXISTS idx_rlf_record ON record_layer_fields(record_name);
     CREATE INDEX IF NOT EXISTS idx_rlf_layer ON record_layer_fields(layer);
     ```
  2. Add `record_layer_mapping` table definition:
     ```sql
     CREATE TABLE IF NOT EXISTS record_layer_mapping (
         id INTEGER PRIMARY KEY AUTOINCREMENT,
         record_name TEXT NOT NULL UNIQUE, -- C++ record name
         pydantic_model TEXT,              -- corresponding Pydantic class (may be NULL)
         pybind_class TEXT,                -- corresponding pybind class (may be NULL)
         sql_table TEXT                    -- corresponding SQL table name
     );
     CREATE INDEX IF NOT EXISTS idx_rlm_pydantic ON record_layer_mapping(pydantic_model);
     ```
  3. Add FTS5 index for field search:
     ```sql
     CREATE VIRTUAL TABLE IF NOT EXISTS record_layer_fields_fts USING fts5(
         field_name,
         field_type,
         notes,
         content=record_layer_fields,
         content_rowid=id,
         tokenize='porter unicode61'
     );
     ```
  4. Increment `SCHEMA_VERSION` to 2
- **Backward compatibility**: Safe to upgrade — new tables don't affect existing ones

#### traceability_server.py
- **Current location**: `scripts/traceability/traceability_server.py`
- **Changes required**:
  1. Add `get_record_mappings` MCP tool:
     ```python
     def get_record_mappings(record_name: str) -> dict:
         """
         Return all four layers' field lists for a record with drift analysis.

         Returns:
             {
                 "record": record_name,
                 "layers": {
                     "cpp": [{"field": "linear_ke", "type": "double"}],
                     "sql": [{"field": "linear_ke", "type": "REAL"}],
                     "pybind": [{"field": "linear_ke", "source": "linear_ke"}],
                     "pydantic": [{"field": "linear_ke", "type": "float"}]
                 },
                 "drift": {
                     "missing_in_pybind": [],
                     "missing_in_pydantic": ["acceleration"],
                     "naming_mismatches": [
                         {"cpp": "penetrationDepth", "pydantic": "penetration_depth"}
                     ]
                 }
             }
         ```
  2. Add `check_record_drift` MCP tool:
     ```python
     def check_record_drift() -> list[dict]:
         """
         Return all records with fields missing from downstream layers.

         Returns:
             [
                 {
                     "record": "InertialStateRecord",
                     "missing_in_pybind": [],
                     "missing_in_pydantic": ["acceleration", "quaternionRate"]
                 }
             ]
         """
         pass
     ```
  3. Register new tools in MCP server tool list
- **Backward compatibility**: New tools only, no changes to existing tools

### Integration Points
| New Component | Existing Component | Integration Type | Notes |
|---------------|-------------------|------------------|-------|
| index_record_mappings.py | traceability_schema.py | Import | Uses `create_schema()` to ensure tables exist |
| index_record_mappings.py | traceability.db | Database write | Populates new tables |
| traceability_server.py | record_layer_fields | Database read | Queries for MCP tools |
| index_record_mappings.py | msd-transfer/*.hpp | File read | Parses BOOST_DESCRIBE_STRUCT macros |
| index_record_mappings.py | msd-pybind/record_bindings.cpp | File read | Parses pybind11 bindings |
| index_record_mappings.py | replay/models.py | File read | Parses Pydantic models |

## Test Impact

### Existing Tests Affected
None — this is a new tooling feature with no impact on existing code or tests.

### New Tests Required

#### Unit Tests
| Component | Test Case | What It Validates |
|-----------|-----------|-------------------|
| BoostDescribeParser | parse_simple_struct | Extracts fields from basic BOOST_DESCRIBE_STRUCT |
| BoostDescribeParser | parse_foreign_key_fields | Identifies ForeignKey<T> fields and extracts target type |
| BoostDescribeParser | parse_repeated_fields | Identifies RepeatedField<T> fields |
| BoostDescribeParser | parse_nested_records | Handles nested sub-records (e.g., CoordinateRecord inside InertialStateRecord) |
| PybindParser | parse_def_readonly | Extracts direct field mappings |
| PybindParser | parse_def_property_readonly | Extracts computed/FK property mappings |
| PybindParser | parse_fk_lambda_pattern | Detects ForeignKey transformation (e.g., `body.id` → `body_id`) |
| PydanticParser | parse_class_definition | Extracts field names and type annotations |
| PydanticParser | infer_cpp_record_name | Correctly infers C++ record from class name or docstring |
| PydanticParser | handle_optional_fields | Parses `field: Type \| None` annotations |
| index_record_mappings.py | populate_layer_fields | All layers' fields correctly inserted into record_layer_fields |
| index_record_mappings.py | populate_layer_mapping | Cross-layer mappings correctly inserted |
| index_record_mappings.py | idempotency | Re-running indexer produces same result (no duplicates) |

#### Integration Tests
| Test Case | Components Involved | What It Validates |
|-----------|---------------------|-------------------|
| full_indexer_run | index_record_mappings.py + traceability.db | All existing records indexed without errors |
| mcp_get_record_mappings | traceability_server.py + database | MCP tool returns correct four-layer comparison for EnergyRecord |
| mcp_check_record_drift | traceability_server.py + database | MCP tool correctly identifies missing Pydantic fields |
| cmake_build_target | CMake + indexer script | `cmake --build --preset debug-traceability` runs new indexer |

## Open Questions

### Design Decisions (Human Input Needed)

1. **SQL Schema Extraction Method**
   - Option A: Parse cpp_sqlite auto-generated schema from BOOST_DESCRIBE (no schema querying needed) — Pros: Simple, no runtime dependency. Cons: Assumes 1:1 mapping of C++ types to SQL types.
   - Option B: Query SQLite schema from an existing .db file generated by cpp_sqlite — Pros: Accurate SQL type names. Cons: Requires running `generate_assets` first.
   - **Recommendation**: Option A (parse from BOOST_DESCRIBE). SQL types are deterministic from C++ types (double→REAL, uint32_t→INTEGER, std::string→TEXT, ForeignKey<T>→INTEGER, RepeatedField<T>→junction table). This matches the existing pattern of indexers that don't depend on build artifacts.

2. **Naming Transformation Detection**
   - Option A: Hard-code known transformations (`camelCase` → `snake_case`, `ForeignKey<T> field` → `field_id`) — Pros: Fast, simple. Cons: Brittle if conventions change.
   - Option B: Use edit distance heuristics to detect likely matches (`penetrationDepth` vs `penetration_depth`) — Pros: More flexible. Cons: False positives possible.
   - **Recommendation**: Option A with explicit notes field. Hard-code the two known transformations (FK suffix, snake_case conversion) and store explanations in the `notes` column. This makes the transformation logic visible in the database.

3. **Intentional Omissions vs. Drift**
   - Some Pydantic models intentionally omit internal/diagnostic fields (e.g., `acceleration`, `quaternionRate` in InertialStateRecord are not exposed to the REST API).
   - Option A: Mark intentional omissions manually (separate config file or comment annotation in Pydantic classes) — Pros: Explicit. Cons: Requires maintenance.
   - Option B: Report all missing fields and let human review determine intent — Pros: Zero config. Cons: Noisy output.
   - **Recommendation**: Option B. The `check_record_drift()` tool returns all missing fields. Humans can ignore known intentional omissions (this is a visibility tool, not an enforcement tool).

4. **FTS Index Scope**
   - Option A: Index only `field_name` and `notes` for quick field search — Pros: Small index. Cons: Can't search by type.
   - Option B: Index `field_name`, `field_type`, and `notes` — Pros: More search flexibility. Cons: Slightly larger index.
   - **Recommendation**: Option B. Type search is useful (e.g., "find all ForeignKey<SimulationFrameRecord> fields"). The index size increase is negligible (~15 records × 4 layers = ~60 rows).

### Prototype Required
None — this is a straightforward indexer following the existing pattern from `index_decisions.py` and `index_symbols.py`. The parsing logic is regex-based for C++ and AST-based for Python, both well-understood.

### Requirements Clarification
1. **Should the indexer track historical changes to record schemas?**
   - Currently designed as snapshot indexer (current state only).
   - Could be extended to snapshot schemas at each commit (similar to `symbol_snapshots`).
   - **Recommendation**: Start with current-state-only. Historical tracking can be added later if needed.

## Implementation Notes

### BOOST_DESCRIBE Parsing Strategy
The macro format is predictable:
```cpp
BOOST_DESCRIBE_STRUCT(RecordName,
                      (BaseClass),
                      (field1, field2, field3));
```

Regex pattern:
```python
BOOST_DESCRIBE_RE = re.compile(
    r"BOOST_DESCRIBE_STRUCT\s*\(\s*(\w+)\s*,\s*\([^)]*\)\s*,\s*\(([^)]+)\)\s*\)",
    re.MULTILINE
)
```

For each field, determine type by scanning backward from the macro to find declarations:
```cpp
cpp_sqlite::ForeignKey<AssetInertialStaticRecord> body;  // ForeignKey
double linear_ke{0.0};                                   // primitive
CoordinateRecord position;                               // nested record
```

### pybind11 Parsing Strategy
Two patterns to detect:
1. Direct field: `.def_readonly("field_name", &RecordType::field_name)`
2. Property (FK): `.def_property_readonly("field_id", [](const Record& r) { return r.field.id; })`

Regex for class blocks:
```python
PYBIND_CLASS_RE = re.compile(
    r'py::class_<msd_transfer::(\w+)>\(m, "(\w+)"\)(.*?)(?=py::class_|$)',
    re.DOTALL
)
```

Within each class block, extract `.def_readonly` and `.def_property_readonly`.

### Pydantic Parsing Strategy
Use Python `ast` module to parse models.py:
```python
import ast

tree = ast.parse(models_content)
for node in ast.walk(tree):
    if isinstance(node, ast.ClassDef):
        # Check if inherits from BaseModel
        for base in node.bases:
            if isinstance(base, ast.Name) and base.id == "BaseModel":
                # Extract fields from class body (ast.AnnAssign nodes)
```

### Database Schema Evolution
New tables are independent of existing traceability tables. Upgrade path:
1. Run `cmake --build --preset debug-traceability` — schema upgrade happens automatically in `create_schema()`
2. New tables are created if they don't exist (CREATE TABLE IF NOT EXISTS)
3. Existing data unaffected

### CMake Integration
Add new target in root `CMakeLists.txt` (following existing pattern):
```cmake
add_custom_target(
  trace-record-mappings
  COMMAND ${CMAKE_COMMAND} -E env
    PYTHONPATH=${CMAKE_SOURCE_DIR}/scripts/traceability
    ${Python_EXECUTABLE} ${CMAKE_SOURCE_DIR}/scripts/traceability/index_record_mappings.py
      ${CMAKE_BINARY_DIR}/docs/traceability.db
      --repo ${CMAKE_SOURCE_DIR}
  DEPENDS trace-git
  WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}
  COMMENT "Indexing record field mappings"
)
```

Add to `debug-traceability` preset dependencies.

## Example Output

### get_record_mappings("EnergyRecord")
```json
{
  "record": "EnergyRecord",
  "layers": {
    "cpp": [
      {"field": "id", "type": "uint32_t", "notes": "inherited from BaseTransferObject"},
      {"field": "body", "type": "ForeignKey<AssetInertialStaticRecord>"},
      {"field": "linear_ke", "type": "double"},
      {"field": "rotational_ke", "type": "double"},
      {"field": "potential_e", "type": "double"},
      {"field": "total_e", "type": "double"},
      {"field": "frame", "type": "ForeignKey<SimulationFrameRecord>"}
    ],
    "sql": [
      {"field": "id", "type": "INTEGER PRIMARY KEY"},
      {"field": "body_id", "type": "INTEGER", "notes": "ForeignKey → _id suffix"},
      {"field": "linear_ke", "type": "REAL"},
      {"field": "rotational_ke", "type": "REAL"},
      {"field": "potential_e", "type": "REAL"},
      {"field": "total_e", "type": "REAL"},
      {"field": "frame_id", "type": "INTEGER", "notes": "ForeignKey → _id suffix"}
    ],
    "pybind": [
      {"field": "id", "source": "id"},
      {"field": "body_id", "source": "body.id", "notes": "ForeignKey lambda"},
      {"field": "linear_ke", "source": "linear_ke"},
      {"field": "rotational_ke", "source": "rotational_ke"},
      {"field": "potential_e", "source": "potential_e"},
      {"field": "total_e", "source": "total_e"},
      {"field": "frame_id", "source": "frame.id", "notes": "ForeignKey lambda"}
    ],
    "pydantic": [
      {"field": "body_id", "type": "int"},
      {"field": "frame_id", "type": "int"},
      {"field": "simulation_time", "type": "float", "notes": "joined from SimulationFrameRecord"},
      {"field": "linear_ke", "type": "float"},
      {"field": "rotational_ke", "type": "float"},
      {"field": "potential_e", "type": "float"},
      {"field": "total_e", "type": "float"}
    ]
  },
  "drift": {
    "missing_in_pybind": [],
    "missing_in_pydantic": [],
    "naming_mismatches": [],
    "extra_in_pydantic": [
      {"field": "simulation_time", "reason": "joined from SimulationFrameRecord via API query"}
    ]
  }
}
```

### check_record_drift()
```json
[
  {
    "record": "InertialStateRecord",
    "missing_in_pybind": [],
    "missing_in_pydantic": [
      "acceleration",
      "quaternionRate",
      "angularAcceleration"
    ],
    "reason": "Internal diagnostic fields not exposed to REST API"
  },
  {
    "record": "CollisionResultRecord",
    "missing_in_pybind": [],
    "missing_in_pydantic": [],
    "naming_mismatches": [
      {"cpp": "penetrationDepth", "pydantic": "penetration_depth"}
    ]
  }
]
```
